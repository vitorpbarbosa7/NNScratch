{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sizes se refere a o número de neurônios em cada camada, por exemplo 10 neurônios na camada de entrada, 5 neurônios na cada oculta e 1 neurônio na camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [10,5,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A partir do número de neurônios em cada camada, gera-se bias aleatórios para as próximas camadas, menos para a camada de entrada\n",
    "- Retorna-se portanto uma lista com vetores colunas com o número de linhas correspondendo ao número de neurônios das camadas ocultas e camada de saída se for o caso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.32887234],\n",
       "        [ 2.36531583],\n",
       "        [-0.57845184],\n",
       "        [-3.19790401],\n",
       "        [-0.61438943]]),\n",
       " array([[-0.36100466]])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.random.randn(y, 1) for y in sizes[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração dos pesos aleatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (3, 6)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Revisão sobre a função zip\n",
    "x = [1,2,3]\n",
    "y = [4,5,6]\n",
    "list(zip(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retornar o número de pesos que deverá ser gerado através da função zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 5]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 5), (5, 1)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(sizes[:-1], sizes[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Os pesos aleatórios são gerados da mesma maneira com o bias, ou seja, com a função np.random.randn\n",
    "- Observa-se que é retornado uma lista com dois arrays. \n",
    "- O primeiro array corresponde aos pesos que ligam os neurônios da camada de entrada com a primeira camada oculta \n",
    "- O segundo array corrresponde aos pesos que conectam os neurônios da primeira camada oculta com a camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.68138786,  0.04389685, -1.10463541, -0.2462504 , -0.49491797,\n",
       "         -0.27663941, -0.12200739,  0.58699268,  1.0484374 , -2.09943768],\n",
       "        [-0.19081019, -0.93693968,  0.23389491, -1.14955355,  0.1847655 ,\n",
       "         -0.94389823,  0.54575563,  0.92201794,  0.16003407,  1.98654868],\n",
       "        [-0.88940788,  0.50941556, -1.03462   , -0.10449545, -0.84407084,\n",
       "         -0.43773836, -2.25029955,  0.07508225,  0.12530092,  0.63388036],\n",
       "        [-0.08152339,  0.90839921, -0.57334633,  0.08802887,  0.85222504,\n",
       "         -0.0899894 , -1.40756457,  0.22310411,  0.42970818, -0.95855779],\n",
       "        [-2.3164256 , -0.06641736, -0.92567138,  1.00323651, -0.42699385,\n",
       "         -0.17217081,  1.96123758,  1.24773313, -0.0602561 ,  0.35067418]]),\n",
       " array([[ 0.07498877,  1.97676829, -1.14874596,  0.14662194, -0.7974334 ]])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    #sizes do tipo lista\n",
    "    def __init__(self, sizes):\n",
    "        \n",
    "        #Passando os atributos da rede neural\n",
    "        #Número de camadas da rede neural\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes [1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x,y in zip(sizes[:-1], sizes[1:])]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pode-se criar um objeto a partir da classe Network e têm-se assim uma arquitetura de rede neural "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Network(sizes=[10,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 5, 1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.28266738],\n",
       "        [ 0.2002924 ],\n",
       "        [-2.03424764],\n",
       "        [-1.059309  ],\n",
       "        [ 1.63589831]]),\n",
       " array([[0.12465653]])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.52018611, -0.49992298, -0.42774913, -0.55542977, -0.08335698,\n",
       "          0.79057802,  0.32757228,  1.44698662, -1.7144653 ,  0.32907682],\n",
       "        [ 0.13605404,  1.66132161,  0.0373024 , -1.21890293, -0.24245149,\n",
       "         -0.09326167,  0.06433936,  0.59675575, -1.67971082, -0.07696922],\n",
       "        [-0.19407594, -0.75720441,  1.00154544,  0.19298743,  0.99193949,\n",
       "          0.19240572,  0.83562101,  0.54713698, -0.79066446,  0.37924776],\n",
       "        [-0.43887663, -0.86591332, -0.31110745, -1.33516429,  0.16270157,\n",
       "         -1.62459603, -0.0241579 ,  1.1076185 ,  0.2977608 ,  0.49779011],\n",
       "        [ 0.33085176, -0.79464027,  1.90571557,  1.73573952, -0.22362687,\n",
       "          0.08590715,  1.32451449, -0.44971274, -0.12769807,  1.06357673]]),\n",
       " array([[ 0.25630611, -1.40427864, -0.91358507,  3.21828838, -0.24869094]])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A função de ativação irá ser aplicada sobre: (W*A + b)\n",
    "- Em que:\n",
    "- W: Matriz dos pesos\n",
    "- A: Matriz de entradas\n",
    "- b: Vetor de bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'z' é uma entrada do tipo vetor ou matriz numpy, mas o numpy aplica automaticamente a função sigmoide de forma elementwise, isto é, na for vetorizada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeedForward\n",
    "- Função feedforward será responsável por dada uma entrada, retornar uma saída, após a aplicação das funções de multiplicação, soma e função de ativação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [4 5 6] 32\n"
     ]
    }
   ],
   "source": [
    "#Revisãozinha np.dot\n",
    "a1 = np.array([1,2,3])\n",
    "a2 = np.array([4,5,6])\n",
    "adot = np.dot(a1,a2)\n",
    "print(a1,a2,adot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Repetindo o código para fins didático né)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    #sizes do tipo lista\n",
    "    def __init__(self, sizes):\n",
    "        \n",
    "        #Passando os atributos da rede neural\n",
    "        #Número de camadas da rede neural\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes [1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x,y in zip(sizes[:-1], sizes[1:])]\n",
    "    \n",
    "    #São realizadas operações sobre a entrada a retorna-se a apóes estas operações\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w,a)+b) #Tá criada em algum lugar do notebook\n",
    "        return a \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualização de como através da função range obtêm-se os mini_batches\n",
    "- Deve-se notar que na função, antes da aplicação da função range, os dados foram embaralhados através da função random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "#Para dar prints horizontais\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800, 832, 864, 896, 928, 960, 992]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,1000,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \n",
    "    #sizes do tipo lista\n",
    "    def __init__(self, sizes):\n",
    "        \n",
    "        #Passando os atributos da rede neural\n",
    "        #Número de camadas da rede neural\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes [1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x,y in zip(sizes[:-1], sizes[1:])]\n",
    "    \n",
    "    #São realizadas operações sobre a entrada a retorna-se a apóes estas operações\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w,a)+b) #Tá criada em algum lugar do notebook\n",
    "        return a \n",
    "        \n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data = None):\n",
    "        # Este tratamento que retorna o tamanho da base de dados de teste será útil no batch_size\n",
    "        training_data = list(training_data)\n",
    "        n = len(training_data)\n",
    "        \n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "        \n",
    "        #Batch_size, ou seja, conjunto de dados que serão utilizados em capa época para a atualização dos pesos\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            #Retornar o conjunto de dados mini_batches a partir do tamanho do batch passado através da variável mini_batch_size\n",
    "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0,n,mini_batch_size)]\n",
    "            \n",
    "            #eta é a taxa de aprendizagem \n",
    "            for mini_batch in mini_batches:\n",
    "                #Chamando o método update_mini_batch desta classe\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "                \n",
    "            #Se os dados de testes forem passados, será impresso uma linha com a avaliação do modelo nestes dados de teste em cada época\n",
    "            if test_data:\n",
    "                #Chamando o método evaluate desta classe\n",
    "                print(\"Epoch {} : {} / {}\".format(j,self.evaluate(test_data),n_test))\n",
    "            else:\n",
    "                print(\"Epoch {} finalizada\".format(j))\n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
